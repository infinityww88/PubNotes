anchoredPosition/anchoredPosition3D

4个anchor定义了父元素中的一个矩形（相对于父元素，所有的元素坐标都是如此，既可以在可以在父元素之内可以在父元素之外，不是必须限定在父元素的矩形内，只是相对于父矩形计算），anchoredPosition是元素的pivot点在这个矩形中的坐标位置，坐标的原点就是与pivot在元素矩形中的位置相似比例的anchor矩形中的位置，坐标轴向右向上为正。如果pivot为（0, 0），则anchor矩形中的左上角为坐标原点; 如果pivot为（0.5, 0.5)，则anchor矩形的中心是原点; 如果pivot为（1, 0.5)，则anchor矩形的右边中点是原点。anchoredPosition就是pivot在这个坐标系中的位置。当anchoredPosition等于（0，0）时，元素的pivot点位于坐标原点上，注意不是元素的中心点，如果pivot是左上角，就是元素左上角在原点上。
anchoredPosition3D只是比anchoredPosition多了一个z轴，控制元素在父元素local坐标系中z轴的位置。

uGUI的自由布局系统是操作在RectTransform上的，只要gameobject具有RectTransform组件，就可被自由布局系统控制，因此如果只是向做定位，然后将这个位置作为他用，可以只加一个只有RectTransform组件的empty gameobject，没有sprite renderer。

RectTransform是Transform的子类，具有和Transform相似的行为。如果一个元素从一个父元素变为另一个父元素的子元素，可以通过SetParent（parent，true）保持元素的可视位置（世界位置）不变，但是RectTransform的anchoredPosition则相对于新的父元素自动被计算。自由布局是比较复杂的，而且每一个元素的anchor和pivot都各自不同，因此计算一个元素局部坐标系空间的位置在另一个元素局部坐标系中的位置（保持可视位置不变）非常复杂，简单的解决办法就是生产一个空的RectTransform，通过设置改变其parent来获得在不同元素局部坐标系中的相对位置（由uGUI系统计算）。

在Layout下的RectTransform受到自动布局系统控制，uGUI系统也是通过自由布局系统来实现自动布局系统的，但是这是在系统之内自动进行的，手动改变自由布局系统的参数是没有用的，因为它会被自动布局系统的修改覆盖掉。可以给元素添加layout element组件，并设置ignore layout选项，使得Layout元素下的自元素不加入自动布局，而是在Layout元素下自由布局，这样一个Layout下既可以有自动布局的元素，也可以有自由布局的元素，可以组合完成各种布局效果。

Unity EventTrigger Raycaster Camera Canvas
Unity内置EventSystem需要使用Raycaster来投射哪些gameobject被选中，内置3中Raycaster：PhysicsRaycaster，Physics2DRaycaster，GraphicRaycaster，Physics(2D)Raycaster必须配置在具有Camera组件的物体上（require typeof Camera），GraphicRaycaster必须配置在具有Canvas的组件上（require typeof Canvas），如果EventTigger组件不起作用，请检查是否配置了Raycaster。
GraphicRaycaster投射所有Graphic元素，就是具有可渲染的部分的UI元素，如果RectTransform没有可渲染部分，则不会被投射到，就像Mask组件一样。

EasyTouch Physics(2D).Raycast() Collider
EasyTouch好像不依赖Camera的Raycaster，EasyTouch应该是内部直接使用物理引擎的Physic(2D).Raycast()来投射选中的物体，因此结果就是场景中的物体如果具有Collider就可以被操作，甚至可以没有渲染部分（只有collider），对于UI元素则使用Canvas GraphicRaycast进行投射，但是如果RectTransform没有可渲染部分，但是具有Collider2D，则仍然可以被操作。
对于具有Collider的物体，只要使用PhysicsRaycast本来就可以操作。

Canvas Mode
ScreenOverlay：Canvas的size就是screen的分辨率，单位也就是像素
ScreenCamera：Canvas被放置在camera正前面（通过distance可以配置到camera的距离）且不可旋转。Canvas总是被缩放至所在处Camera frustum的截平面大小，即canvas四边总是落在frustum上，因此在最终视口上canvas总是占据整个screen大小。但是Canvas的size仍然是screen的分辨率大小，和ScreenOverlay一样，UI元素的大小单位也是基于这个分辨率，这样UI布局时大小设置就和ScreenOverlay一样。ScreenCamera和ScreenOverlay的区别是，camera模式下，UI元素都是在世界中放置，和场景中的物体一样，也满足透视投影，近大远小（通过Z轴设置），并且和场景物体之间可以相互遮挡，并且可以旋转，而ScreenOverlay总是覆盖在场景上，不可旋转，没有透视效果。因为Camera模式下，UI元素是世界中的物体，因此可以和其它物体比较大小，因为Canvas的size总是screen的分辨率，因此要确定UI在世界中的大小就要使用screen的size和canvas所在截平面的大小作为比例，即UI元素（包括Canvas）的size和坐标的单位不是一个世界单位，而是frustum_size / screen_size个世界单位，当然如果不需要和场景物体比较大小，则不必考虑这个比例，直接将UI元素的单位视为像素即可。
World：Canvas完全就是世界中的物体，大小单位也是世界单位。

Canvas Scaler
CanvasScaler本质作用就是通过缩放Canvas的width／height size来缩放所有UI元素的大小。
Canvas的size在Overlay和Camera模式下是强制的，所有UI元素的size都是相对于这个大小确定的，可以认为UI元素的大小和坐标单位都是Canvas的逻辑单位，逻辑单位的真正大小由Canvas的size和Canvas的真正大小（screen的分辨率）的比例确定的，所以可以通过缩放Canvas的size来缩放逻辑单位的真正大小，进而缩放全部的UI元素真正大小。CanvasScaler的所有mode都是用来确定Canvas的width和height的，UI元素的width／height和position的值不会被影响，这也是CanvasScaler被称为Canvas的scaler的原因。
因为World模式下，Canvas的真正大小不是固定的（Overlay和Camera模式下，Canvas真正大小总是视口大小），Canvas和UI元素的单位是世界坐标系，单位也是世界坐标，数值大小直接确定Canvas和UI的真正大小和位置，所以不需要用CanvasScaler来缩放Canvas的width和height（另外，CanvasScaler是用来做屏幕UI适配的，所以需要Scaler来根据设备情况缩放UI元素，而World模式下，UI是世界场景的一部分，是用来实现场景内UI的，而不是屏幕UI的，因此不需要考虑屏幕适配），此时CanvasScaler的scale模式锁定为world，即不能用来改变Canvas的width／height。Overlay和Camera模式下，都有相同的三种scale模式可以选择：
Constant Pixel Size
Scale With Screen Size
Constant Physical Size
CanvasScaler除了缩放UI元素大小，还有一个功能就是缩放sprite的像素密度，即Reference Pixels Per Unit选项，所有Pixels Per Unit相关的事情都受其影响，包括动态生产的字体的size，sliced image的border，image set native size之后的size，所有scale mode都具有这个功能，包括world模式。
Overlay／Camera模式下Canvas的真正大小总是屏幕大小。Canvas的width／height将这个大小面积分成相应数量的单位块，所有UI元素的positin／size都是这个单位块为单位进行布局的。
Constant Pixel Size模式下Canvas的分辨率默认就是screen的分辨率，但是可以通过Scale Factor一致缩放Canvas的分辨率，从而缩放UI元素。
Scale With Screen Size提供了一种通过Reference Resolution缩放Canvas的resolution（width/height)，使其以各种方式匹配Reference Resolution。Canvas的缩放总是一致的，即最终其resolution和screen的resolution的aspect radio是相等的，否则就会出现不一致缩放。
如果Screen的resolution和Reference Resolution的aspect radio是一致的，则Canvas的resolution就等于Reference Resolution。否则，有三种方式确定Canvas的resolution如何匹配reference的resolution（此时无论如何Canvas不能完全显示reference resolution，要不大一部分，要么小一部分，或者在wdith／height的一边大一部分，而另一边小一部分，但是整体而言与reference resolution是接近的）：
Expend：使Canvas的width／height中与reference相比最小的那个等于reference，另一个则按照screen的aspect radio计算得到，则Canvas（Screen）总是最小包含reference resolution。
Shrink：与Expend相反，使Canvas的width／height中与reference相比最大的那个等于reference，另一个则按照screen的aspect radio计算得到，则Canvas（Screen）总是最大的被包含在reference resolution中。
Match Width or Height：使用Match（0-1）变量控制如何根据reference计算Canvas的resolution。Match=0时，Canvas的width=reference的width，height根据screen的aspect radio计算得到；Match=1时，Canvas的height=reference的height，width根据screen的aspect radio计算得到；Match在0-1之间时则插值reference的width和height的影响从而得到相应的Canvas的resolution。

Canvas Group
CanvasGroup可以控制一组UI元素的某些属性，而不必单独控制为其中每个元素的属性。
CanvasGroup中提供的属性影响它所在GameObject的UI元素和其所有子UI元素。

EasyTouch既可以和场景中的物体交互，又可以和uGUI元素交互，但是因为uGUI系统本身内置有和UI元素的交互逻辑，因此EasyTouch和uGUI配合时需要考虑是否兼容uGUI事件系统。

Unity UI compatibility：
EasyTouch doesn't fire gesture events if touch is over a UIElement， 禁用EasyTouch和UI的交互，EasyTouch不发送手势事件。若想UI元素使用EasyTouch，必须关闭此选项，否则就会UI元素不会响应EasyTouch设置的回调函数。
这个选项只是用来开启／关闭EasyTouch是否在元素上发送手势事件（即所称之为的Unity UI compatibility，对与原有Unity EventSystem没有任何影响，EasyTouch只会增加Unity的能力，而不会减少），这个选项对于场景中的物体没有影响。

当uGUI中有任何UI元素使用QuickGesture组件，EasyTouch会自动disable此选项。但是如果使用EasyTouch singleton的事件委托或者EasyTouchTrigger时，必须手动关闭此选项。

当EasyTouch和uGUI元素交互时，回调函数的gesture参数中pickedUIElement代表选择的UI元素，而不是pickedGameObject，后者此时是空的，这是因为EasyTouch可以透过UI元素同时选中UI和场景中的物体，因此出现两个picked target，说明EasyTouch是将对UI对交互和对场景物体对交互作为两个layer来处理的。当使用ETT是，总是可以同时选中UI和它下面的物体，使用QuickGesture时，默认UI是遮挡物体的，即只有UI的手势触发，除非设置QuickGesture的Allow Over UI Element为true，则与ETT是一致，即同时向UI和物体发送手势事件。

EasyTouch5中有4种监听手势的方法：QuickGesture，On_XXX事件委托，EasyTouch.current轮训检测，EasyTouchTrigger
1）QuickGesture的手势事件总是要求在其所在物体上触发
2）代码中EasyTouch.On_XXX += handler事件委托（以及EashTouch5的轮训检测EasyTouch.current）总是全局触发，即不检测是否在代码组件所在的物体或UI上，代码中需要使用EashTouch.pickedTarget来判断是否选中指定的UI或物体（但是当Unity UI compatibility Eabled时，点击在UI元素EasyTouch不会发送手势事件，此时EasyTouch将射线检测让给uGUI的事件系统，只有在UI元素之外时EasyTouch才会发送事件），同时其总是同时选中UI和UI覆盖的物体
3）ETT中可以选择是否检测手势发生在自己身上／任何地方／其它指定的物体，只有满足指定的条件时才会发送手势，同时还可以指定接受事件的物体，自己或其它指定的物体。

EasyTouch射线检测有两种类型，对于UI，需要在ETT中的Testing on选中UI，此时使用GraphicRaycaster检测，对于Gameobejct需要选中Object3D，此时使用PhysicRaycaster检测，物体需要有collider。EasyTouch配置模块中的Enable 2D collider应该是开启使用Physic2DRaycaster对Collider2D的场景物体检测。

Auto update picked Unity UI／Object选项：EasyTouch在每一帧发送的事件参数gesture中pickedObject/pickedUIElement是否重新使用射线检测进行更新（如果更新pickedTarget就可能不是事件开始时的target，而且在事件过程中随pointer移动不断变化）。关闭时，同一个事件的每一帧回调函数中，gesture参数的pickedTarget都是最开始的object／UI，而且不会变化；开启时，每一帧过程中EasyTouch发送事件参数时都重新检测并更新gesture中的pickedTarget参数。

EasyTouchTrigger和Unity自带的EventTrigger使用方法几乎一样，区别在于：
1）EventTrigger相对于ETT提供的事件比较基础，对于更高级的事件swipe／pinch／longtap／doubletap等等仍然需要封装，而ETT提供来非常丰富的高级手势。介于这些手势是非常常用的事件，因此建议使用ETT
2）EventTrigger只能检测组件所在的UI／GameObject上的事件，而ETT可以检测所在物体／指定物体／任何区域的事件，并且事件发送的目的地也可以指定
3）EventTrigger自动使用场景中所有具有PhysicsRaycaster组件的Camera进行射线检测，而ETT需要在EasyTouch配置组件中配置需要的Camera，默认MainCamera自动添加，而且ETT应该是内部使用Physics.Raycast进行检测而不需要Camera具有PhysicsRaycaster，但是对Canvas仍然依赖GraphicRaycaster
4）ETT的drag对UI元素无效，因为ETT提供了swipe事件，swipe和drag应该是相同的事件，只是名字不同，因此使用ETT时应该使用swipe事件（swipe听起来是比drag更高级的事件，因为指针滑动未必是向拖拽物体），但是drag对于GameObject是有效的，但是为了统一起见，还是使用swipe事件。EventTrigger只提供drag事件，对UI元素和GameObject都有效
5）EventTrigger等价的代码实现有3种方式：
a) 组件实现事件接口（IPointerEnterHandler)
b) 组件继承EventTrigger，并override对应方法OnPointerEnter。EventTrigger已经继承自MonoBehaviour。
c) 获取当前物体上的EventTrigger组件，GetComponent<EventTrigger>()，向其添加EventTrigger.Entry，entry指定eventId（EventTriggerType.PointerEnter），调用entry.callback.AddListener添加事件处理函数
ETT等价的代码实现有2种：
a) EasyTouch.On_TouchStart += TouchStartHandler
b) EasyTouch.current在每帧update时轮训检测

EventSystem
有三个组件：EventSystem、StandaloneInputModule、TouchInputModule，后面两个组件都继承自BaseInputModule。
EventSystem组件主要负责处理输入、射线投射以及发送事件。一个场景中只能有一个EventSystem组件，并且需要BaseInputModule类型组件的协助才能工作。EventSystem在一开始的时候会把自己所属对象下的BaseInputModule类型组件加到一个内部列表，并且在每个Update周期通过接口UpdateModules接口调用这些基本输入模块的UpdateModule接口，然后BaseInputModule会在UpdateModule接口中将自己的状态修改成'Updated'，之后BaseInputModule的Process接口才会被调用。
BaseInputModule是一个基类模块，负责发送输入事件（点击、拖拽、选中等）到具体对象。EventSystem下的所有输入模块都必须继承自BaseInputModule组件。StandaloneInputModule和TouchInputModule组件是系统提供的标准输入模块和触摸输入模块，我们可以通过继承BaseInputModule实现自己的输入模块。
   除了以上两个组件，还有一个很重要的组件通过EventSystem对象我们看不到，它是BaseRaycaster组件。BaseRaycaster也是一个基类，前面说的输入模块要检测到鼠标事件必须有射线投射组件才能确定目标对象。系统实现的射线投射类组件有PhysicsRaycaster, Physics2DRaycaster, GraphicRaycaster。这个模块也是可以自己继承BaseRaycaster实现个性化定制。
  总的来说，EventSystem负责管理，BaseInputModule负责输入，BaseRaycaster负责确定目标对象，目标对象负责接收事件并处理，然后一个完整的事件系统就有。
每帧Update时，EventSystem调用Input模块获取输入，根据输入使用所有Raycaster进行射线检测，向每个射中的物体发送事件（以及更新Input模块，如按下的鼠标，游戏杆的状态）

因为3d物体上没有canvas上边的GraphicRaycaster所以要Main Camera上添加Physics Raycaster，就相当于UI上的GraphicRaycaster。

OffsetMax是元素边框（蓝色框）right-up conner相对于right-up anchor(AnchorMax)的相对距离
OffsetMin是元素边框（蓝色框）left-bottom conner相对于left-bottom anchor(AnchorMin)的相对距离
sizeDelta就是offsetMax - offsetMin
sizeDelta元素相对于anchor矩形的大小差距
sizeDelta=Vector2(0, 0)表示元素大小和anchor矩形大小相等

Unity Anchor UI布局定位与其它UI系统的定位有显著不同，其它UI系统的布局自元素相对于父元素左上角为原点，x轴向右，y轴向下的坐标系定位
anchorPosition并不是相对于父元素，而是相对于本元素的anchor在父元素划出的矩形，然后计算本元素povit在元素矩形中的位置，找到anchor矩形中相等比例的位置，以此作为原点，x轴向右，y轴向上，之后元素的anchorPosition就是元素povit在这个坐标系中的位置，改变元素的anchorPosition来改变元素的位置。RectTransform是建立的transform之上的完全不同的布局系统，只是使用transform设置最终的position／rotation／scale，因此在UI布局中transform只是低层实现细节，直接设置transform，或者无效并被RectTransform布局系统覆盖，或者即使可以设置，也需要实现一套和UI布局系统一样的机制来根据RectTranform确定最终transform的状态，这需要了解比RectTransform布局更多的知识，因此UI布局中应该只使用RectTransform而不是transform。RectTransform属于更上层的机制，transform属于低层实现细节，RectTranform在transform基础之上添加了更多的数据，并有一套布局系统代码根据这些数据更新transform。

操作uGUI已定要使用anchorPosition(3D)，不要使用transform.position(localPosition)，无法得知uGUI布局系统底层如何使用position。设置uGUI元素的Z值使用anchorPosition3D.z，z=0，UI元素落在父元素平面上。
UI元素的渲染关系只和元素siblingIndex有关，与Z值无关。siblingIndex更大的优先渲染。
uGUI布局系统的更新很靠后，至少在LateUpdate之后，但是在EndOfFrame之前，在本帧对布局系统的修改（将新的元素添加到gridlayout）必须等到uGUI更新之后才能获得最新的UI数据，而无法立刻得到（新的UI元素的anchorPosition需要在系统更新之后才能变成新的在gridlayout中的值）。如果需要做动画，只能使用异步的方式，或者在下一帧的update，或者启动coroutine，waitforendofframe，然后使用新的UI数据。

GameObject（Sprite）不适合用来实现world内UI系统
1）没有代表元素大小的矩形区域（width／height），而每个UI元素本质上就是一个矩形
2）没有自动／自由布局系统
3）需要collider进行射线检测
4）不方便在不同元素的坐标系之间进行坐标转换，坐标与元素区域比较，以及将屏幕坐标转换为元素坐标系内的坐标
5）元素的pivot是固定的
6）UI相关的插件无法与GameObject协同工作
7）需要通过Z轴或sprite order控制渲染顺序
uGUI一整套方案都是为UI设计提供的，除非十分简单的“UI”，例如不需要考虑元素大小，不需要布局，不需要坐标转换等等，正常的UI系统都应该使用uGUI实现。

UI元素的“position”（anchorPosition），是相对于父元素定义的，但不是父元素本身的矩形，而是本元素的4个anchor conner在父元素矩形中定义的矩形，anchor conner的值是父元素矩形中标准化的值，pivot的值是pivot点在元素矩形中的位置。
RectTransformUtility.ScreenPointToLocalPointInRectangle
用来获得屏幕上的点在指定RectTransform矩形中的位置，以元素的pivot点为原点，x轴向右，y轴向上。

其他UI系统的元素和uGUI系统的元素的一个很大不同点就是坐标系原点的定义
前者UI元素的pivot总是在左上角，而后者UI元素的pivot可以自由定义
前者UI元素的position（pivot即左上角的位置）被定义的坐标系是以父元素的左上角为原点，后者UI元素的position被定义的坐标系是父元素指定矩形内子元素元素pivot等比例所在的位置，其和父元素的pivot没有关系，而与本元素的pivot有关系。

UI元素的transform == transform.GetComponent<RectTransform>()

程序员的最高荣耀与追求是快速实现产品，转化经济利益，而不是编写花哨精巧的代码。现在已经不是过去硬件受限的年代，机器的成本和时间越来越廉价，而程序员的时间越来越宝贵，况且过早优化是万恶之源。不要一遇到精巧代码的挑战就深陷其中，无论如何，这些技巧都是你能写出来的，不是这一次不写，就失去了挑战的机会，就像数学家庞加莱所坚持的，不在一个问题上浪费太多时间，在这个问题上失去的思考会在之后的问题上重现。如果一个功能既可以编写精巧代码花费很多时间实现，也可以使用简单暴力的方法很快的实现，一定要选择后者，快速实现，节约程序员的时间是最高准则，可能代码看起来很初级，可能需要花费额外的多余不必要的内存存储，但是都没有关系，只有证明这真的成为瓶颈，再去优化。能够多快的实现一个系统才是优秀程序员的衡量标准。

哈夫曼编程策略：自底向上，一个小功能一个小功能实现测试，直到这个小功能无误了，在开发其他的小功能，更高层的功能也是将下层小功能作为基础功能而实现的高层的小功能。只有这样才能构建出真正健壮宏伟的系统。绝不能试图开始就构建整个系统，这是不入门的程序员干的事情。

允许一开始不去完全了解整个系统／功能的真正面貌，只实现当前已知的部分，随着一个个已知的小功能的实现，未知的部分也随之暴露，成为已知的部分，依次迭代，最终系统呈现完整面貌的时刻就是系统实现之时，程序员在此过程完全没有压力且乐在其中，因为不必同时考虑其他问题，不必为整个系统的设计负责，因为此时根本就没有整体系统设计，同时不断实现的一个个小功能功也为程序员提供了正向反馈
自顶向下只有在对整个系统十分熟悉清楚的情况下才有效，否则随便系统中的一个不熟悉的小细节就可能导致整个方案不可用，需要花费很多精力绕过去，并且现实中很难真正对整个系统有着自定向下的完全理解，因此绝大多数情况下，自定向下的实现是效率低下的，并且对程序员造成很大的精神压力，自顶向下很难给予程序员不间断的正向反馈。
自顶向下的开发导致的另一个问题是测试难度几何级数的暴增，当把全部功能都实现之后再去调试，各个模块之间的问题相互影响牵扯，而此时已无法单独的测试每个模块了，因为除非把整个系统运行起来，否则没办法测试，而把整个系统运行起来则需要每个模块都如期工作，这就陷入两难的地步，是不可能实现的。而自底向上的方法，是在既有的已经测试良好完全可运行的系统上添加一个小模块，此时可以非常容易的把系统运行起来，因为添加的代码非常少，同时非常容易测试，因为只添加了一个功能。测试完之后，这个新的模块就算是添加到已实现的系统模块，因为不必担心这个模块的细节，就可以开始实现和这个模块毗邻相关的模块（即相关的模块暴露出来），然后就像之前的模式一样迭代，直到整个系统构建完毕（即类似哈夫曼编码，有类似单源最短路径或者A*算法，都是把以已经确定的部分添加到，已知集合，然后利用已知集合确定未知的部分哪些可以变成已知，将其添加到已知集合中，不断如此，未知部分就会变的越来越小，直到全部已知）

总之，自底向上才是王道，自顶向下是错误的。任何时候，都不要心焦气躁，不要试图揠苗助长，如果一个系统／模块／功能不完全了解，只能说明它还不够基础，还不够小，不要尝试了解它，而是去实现确定已知的必要部分，一旦实现了它，未知的部分就会自然而然的暴露。每次程序员只会面对最少的未知，并且能快速的得到正向反馈，会进一步激发其热情。

自底向上不一定都是实现已知系统的必要部分，可以是探路式的实现一些小模块，用来窥视更大的系统面貌，这些模块可能最终不会用到最终的系统中，这是自底向上过程的应有之义，这些不使用的模块即使放在系统中也无伤大雅，并且可能在未来会用得上。

生活中也是一样，无论任何时候，揠苗助长，急于求成都是南辕北辙，妄图走捷径结果都是走更大的弯路，稳扎稳打，步步为营才是最快的捷径。

学习一种知识框架最好的方式就是尝试使用它，只是学习纸面知识无法真正掌握，只有在使用的过程中，各种问题才会逼着你去深入的了解各种细节。但是需要一开始先完全从纸面了解整个系统完整面貌，知道它是干什么的，能用它来做什么事。因此学习新知识的最有效方式就是先从纸面全面整体的了解，但这只是第一步，接下来要开始尝试使用它去实现一些东西，最后就是经常练习熟练之。在实践的过程中，会发现诸多书面上没有呈现或者学习时没有注意到的知识，抑或是理解有误的知识，要及时将其记录下来，防止遗忘，一旦遗忘，就会在之后重新发现这些知识，则本次的工作就算浪费了，尽可能的减少未知的知识，因为未知带来精神压力，当在实践过程中不断遇到不符合预期的现象就会使信心激情受到打击，所以一旦未知变成已知一定及时记录，只要记录一次差不多就不会忘记，而且有了记录，之后还可以温习且不必重新发现，但是不记录的话，知识很可能被遗忘，因为大脑的记忆需要不断的重复，而现在只在发现的时候记忆了一次，之后的重复过程可能需要重新发现，任何时候重复不必要的工作都是令人恼怒的。

unity3d是一生都要学习玩耍的东西，不在乎一朝一夕，以后有足够的时间了解它的方方面面。
